{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHB7tQJQuiLH",
        "outputId": "3690d79e-283e-4f3c-fbd5-fbcf461ab984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/bit_conference/"
      ],
      "metadata": {
        "id": "9LVD6rfruttC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45e9ce19-67b5-4475-8efc-aaa1d4c1aeb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1YDrmXvwQeDTF3AVegVo_-qlULY2-1-qE/bit_conference\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이미지 생성"
      ],
      "metadata": {
        "id": "JYqfso5tuqC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers --upgrade"
      ],
      "metadata": {
        "id": "iRxyvdkduwI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install invisible_watermark transformers accelerate safetensors"
      ],
      "metadata": {
        "id": "nX2K_sU6uqub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import DiffusionPipeline\n",
        "import torch\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    variant=\"fp16\"\n",
        ")\n",
        "pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "CsGgLkzeuxh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "df_gen2 = pd.read_csv('coding/df_gen2.csv')\n",
        "\n",
        "# id 칼럼에서 4자리 숫자 부분을 추출하는 함수\n",
        "def filter_ids(id_str):\n",
        "    match = re.search(r'(\\d{4})$', id_str)  # id 끝 부분에서 숫자(0001~1000) 추출\n",
        "    if match:\n",
        "        return int(match.group(1)) <= 500  # 0001~0500까지만 남기기\n",
        "    return False\n",
        "\n",
        "# 필터링 적용\n",
        "df_gen2 = df_gen2[df_gen2[\"id\"].apply(filter_ids)].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "dcNdWl3vuzBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 감정 리스트 정의\n",
        "emotions = [\n",
        "    \"Exciting\", \"Hopeful\", \"Romantic\",\n",
        "    \"Heartwarming\", \"Calm\",\n",
        "    \"Sad\", \"Stress\", \"Lonely\"\n",
        "]\n",
        "\n",
        "# 각 감정별로 데이터프레임을 생성하고 변수에 저장\n",
        "for emotion in emotions:\n",
        "    globals()[f\"df_{emotion.lower()}\"] = df_gen2[df_gen2[\"label\"] == emotion].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "oRCLwJrBu01w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_lonely = df_lonely.iloc[232:,]"
      ],
      "metadata": {
        "id": "XSTzoDwSksSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 감정 리스트 정의\n",
        "emotions = [\n",
        "    \"Exciting\", \"Hopeful\", \"Romantic\",\n",
        "    \"Heartwarming\", \"Calm\",\n",
        "    \"Sad\", \"Stress\", \"Lonely\"\n",
        "]\n",
        "\n",
        "# Google Drive의 기본 저장 경로\n",
        "base_dir = \"/content/gdrive/MyDrive/bit_conference/image_gen\"\n",
        "os.makedirs(base_dir, exist_ok=True)  # 기본 디렉토리 생성 (없으면 생성)\n",
        "\n",
        "# 각 감정별 데이터프레임을 순회하며 이미지 생성\n",
        "for emotion in emotions:\n",
        "    df_emotion = globals()[f\"df_{emotion.lower()}\"]  # 감정별 데이터프레임 가져오기\n",
        "    save_dir = os.path.join(base_dir, emotion.lower())  # 감정별 디렉토리 설정\n",
        "    os.makedirs(save_dir, exist_ok=True)  # 감정별 디렉토리 생성\n",
        "\n",
        "    print(f\"Processing {emotion}...\")\n",
        "    for index, row in tqdm(df_emotion.iterrows(), total=len(df_emotion), desc=f\"Generating {emotion} Images\"):\n",
        "        # 원래 텍스트에 감정 정보 추가 (예: \"with a romantic atmosphere\")\n",
        "        prompt = f\"{row['text']} with a {emotion.lower()} atmosphere\"\n",
        "        image = pipe(prompt=prompt).images[0]  # 이미지 생성\n",
        "        file_name = f\"{row['id']}.png\"  # id 칼럼을 파일명으로 사용\n",
        "        file_path = os.path.join(save_dir, file_name)  # 파일 경로 설정\n",
        "        image.save(file_path)  # 이미지 저장\n",
        "\n",
        "print(\"모든 감정별 이미지 생성 및 저장 완료!\")\n"
      ],
      "metadata": {
        "id": "Gm-QinLnQT4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이미지 증강"
      ],
      "metadata": {
        "id": "wO_K2RDoxMw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations opencv-python"
      ],
      "metadata": {
        "id": "F_ame7lIRoyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7918818f-3ce0-42f5-ba7b-62a63c34041d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (2.0.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.13.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations) (2.10.6)\n",
            "Requirement already satisfied: albucore==0.0.23 in /usr/local/lib/python3.11/dist-packages (from albumentations) (0.0.23)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations) (3.11.3)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations) (6.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotions = [\"exciting\", \"hopeful\", \"heartwarming\", \"calm\"]\n",
        "emotions = [\"romantic\", \"sad\", \"stress\", \"lonely\"]"
      ],
      "metadata": {
        "id": "kkh9i8WVxrM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import numpy as np\n",
        "from tqdm import tqdm  # tqdm 추가\n",
        "\n",
        "# 기본 경로 설정\n",
        "base_path = \"/content/gdrive/MyDrive/bit_conference/image_gen/\"\n",
        "emotions = [\"exciting\", \"hopeful\", \"heartwarming\", \"calm\",\n",
        "            \"romantic\", \"sad\", \"stress\", \"lonely\"]\n",
        "\n",
        "# 증강 파이프라인 설정\n",
        "transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),        # 좌우 반전\n",
        "    A.Rotate(limit=30, p=0.5),       # -30 ~ +30도 회전\n",
        "    A.RandomBrightnessContrast(p=0.5),  # 밝기 및 대비 조절\n",
        "    A.GaussianBlur(blur_limit=(3, 7), p=0.3),  # 가우시안 블러\n",
        "    A.HueSaturationValue(p=0.3),     # 색상 변경\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# 증강 실행\n",
        "for emotion in emotions:\n",
        "    input_folder = os.path.join(base_path, emotion)  # 원본 이미지 폴더\n",
        "    output_folder = os.path.join(base_path, f\"{emotion}_aug\")  # 증강 이미지 저장 폴더\n",
        "\n",
        "    # 증강된 이미지 저장 폴더 생성\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # 원본 폴더 내 파일 리스트 가져오기\n",
        "    image_files = [f for f in os.listdir(input_folder) if f.endswith(\".png\")]\n",
        "\n",
        "    print(f\"\\nProcessing {emotion}: {len(image_files)} images\")\n",
        "\n",
        "    # tqdm을 사용하여 진행 상태 표시\n",
        "    for img_name in tqdm(image_files, desc=f\"Augmenting {emotion}\", unit=\"img\"):\n",
        "        img_path = os.path.join(input_folder, img_name)\n",
        "        image = cv2.imread(img_path)\n",
        "\n",
        "        if image is None:\n",
        "            print(f\"이미지를 불러올 수 없습니다: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # OpenCV는 BGR, 변환 필요\n",
        "\n",
        "        # 3개의 증강 이미지 생성\n",
        "        for i in range(3):\n",
        "            augmented = transform(image=image)[\"image\"]\n",
        "            augmented = augmented.permute(1, 2, 0).numpy()  # Tensor를 Numpy로 변환\n",
        "            augmented = cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR)  # 다시 BGR로 변환\n",
        "\n",
        "            aug_img_name = f\"{img_name.split('.')[0]}_aug_{i}.png\"\n",
        "            cv2.imwrite(os.path.join(output_folder, aug_img_name), augmented)\n",
        "\n",
        "    print(f\"증강 완료: {output_folder}\")\n"
      ],
      "metadata": {
        "id": "rKAHy2D_RpGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "337d0e59-1f73-4a11-edca-5d865c5c6fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing exciting: 423 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting exciting: 100%|██████████| 423/423 [04:18<00:00,  1.64img/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "증강 완료: /content/gdrive/MyDrive/bit_conference/image_gen/exciting_aug\n",
            "\n",
            "Processing hopeful: 397 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting hopeful: 100%|██████████| 397/397 [03:47<00:00,  1.75img/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "증강 완료: /content/gdrive/MyDrive/bit_conference/image_gen/hopeful_aug\n",
            "\n",
            "Processing heartwarming: 480 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting heartwarming: 100%|██████████| 480/480 [04:01<00:00,  1.99img/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "증강 완료: /content/gdrive/MyDrive/bit_conference/image_gen/heartwarming_aug\n",
            "\n",
            "Processing calm: 446 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting calm: 100%|██████████| 446/446 [03:38<00:00,  2.04img/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "증강 완료: /content/gdrive/MyDrive/bit_conference/image_gen/calm_aug\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}